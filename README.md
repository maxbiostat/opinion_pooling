# Opinion pooling and log-linear mixtures (logarithmic pooling)

Bits and pieces on (logarithmic) opinion pooling.


### Bayesian inference for the weights in logarithmic pooling

[Luiz Max de Carvalho](http://lmfcarvalho.org/about/)<sup>1</sup>, [Daniel Villela](http://www.procc.fiocruz.br/Members/dvillela)<sup>2</sup>, [Flavio Coelho](http://fccoelho.github.io/)<sup>1</sup> and [Leonardo Bastos](http://www.procc.fiocruz.br/Members/lsbastos) <sup>2</sup>
 
<sup>1</sup> School of Applied Mathematics, Getulio Vargas Foundation (FGV), Rio de Janeiro -- RJ, Brazil.

<sup>2</sup> Program for Scientific Computing, Oswaldo Cruz Foundation, Rio de Janeiro -- RJ, Brazil.

**Abstract** 

Combining distributions is an important issue in decision theory and Bayesian inference.
Logarithmic pooling is a popular method to aggregate expert opinions by using a set of weights that reflect the reliability of each information source.
However, the resulting pooled distribution depends heavily on set of weights given to each opinion/prior and thus careful consideration must be given
to the choice of weights.
In this paper we review and extend the statistical theory of logarithmic pooling, focusing on the assignment of the weights using a hierarchical prior distribution. 
We explore several statistical applications, such as the estimation of survival probabilities, meta-analysis and Bayesian melding of deterministic models of population growth and epidemics.
We show that it is possible learn the weights from data, although identifiability issues may arise for some configurations of priors and data.
Furthermore, we show how the hierarchical approach leads to posterior distributions that are able to accommodate prior-data conflict in complex models.
[[ArXiV]](https://arxiv.org/abs/1502.04206) 
